---
title: "p8105_hw2_iho2104"
author: "Ixtaccihuatl Obregon"
date: "2023-10-03"
output: github_document
---


```{r}
library(tidyverse)
library(readxl)
```

# Problem 1 

clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

```{r clean_538_snp}
snp = 
  read_csv("snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r clean_538_unemp}
unemployment = 
  read_csv("unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

join the datasets by merging 'snp' into 'pols', and merging 'unemployment' into the result.

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

# Problem 2

specify the sheet in the Excel file and omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel. use reasonable variable names and omit rows that do not include dumpster-specific data. 

The data include a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset. Update the data to include a new homes_powered variable based on this calculation.

```{r clean_mr_trash_wheel}

mr_trash_wheel = read_excel("202207 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range= "A2:N549", col_names = TRUE) |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), convert = TRUE) |> 
  mutate(homes_powered = weight_tons * 500/30) 
```




```{r clean_prof_trash_wheel}

prof_trash_wheel = read_excel("202207 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range= "A2:M96", col_names = TRUE) |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), convert = TRUE) |> 
  mutate(homes_powered = weight_tons * 500/30) 
  
```

```{r clean_gywnnda_trash_wheel}
gwynnda_trash_wheel = read_excel("202207 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range= "A2:K108", col_names = TRUE) |> 
  janitor::clean_names() |> 
  separate(date, into = c("year", "month", "day"), convert = TRUE) |> 
mutate(homes_powered = weight_tons * 500/30) 
  
```

```{r merge_files}
all_trash_merge = 
  bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel) |> relocate(homes_powered) |> 
relocate(dumpster)

```

```{r total_tons_of_prof_trash_wheel}
prof_weight_tons = prof_trash_wheel  |> 
  summarise(sum(weight_tons))
```

```{r total_cigerattes_of_trash_gywnnda}
gwynnda_trash_wheel |> 
  filter(month == "7", year == 2021) |> 
  summarise(sum(cigarette_butts))
```

Use 'sheet=' to specify which excel sheet is being used. 'Use 'skip =' to omit the first row from the data set. Used 'seperate()' to seperate the "year-month-day" into 3 different columns. Used the 'mutate()' to calculate the 'homes_powered' Merged the 3 df using 'bind_rows'. Number of Observations was 747. Total weight of trash collected by Professor Trash Wheel was 190.12 tons. Total number of cigerattes collected by Gwynnda in July 2021 was 16300. 

## Problem 2

Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). 

```{r clean_mci_baseline}
mci_baseline_df = read_csv("MCI_baseline.csv", skip = 1) |> 
janitor::clean_names() |> 
  mutate(
    sex = case_match(
      sex,
      1  ~ "male",
      0 ~ "female"
    ),
    apoe4 = case_match(
      apoe4,
      1 ~ "carrier",
      0 ~ "non-carrier"
    ), 
    age_at_onset = as.numeric(age_at_onset)
    ) |> 
  filter(age_at_onset > current_age | is.na(age_at_onset))
str(mci_baseline_df) 
view(mci_baseline_df)
```

Discuss important steps in the import process and relevant features of the dataset. 
'Use 'skip =' to omit the first row from the data set. Used the 'mutate()' function to change 'sex' and 'apeo4' into character values 'male/female' and 'carrier/non-carrier', respectively.
471 participants were recruited to the study.
The average baseline age was 65.5 years. 

Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values.

```{r clean_mci_amyloid_df}
mci_amyloid_df = read_csv("mci_amyloid.csv", skip = 1) |> 
janitor::clean_names() |>
rename(id = study_id,
      year_0 = baseline, 
       year_2 = time_2, 
       year_4 = time_4,
       year_6 = time_6,
       year_8 = time_8) |> 
  pivot_longer(
    year_0:year_8, 
    names_to = "time", 
    values_to = "biomarker"
    ) 
```
```{r age_baseline_age}
avg_baseline_age = mci_baseline_df |> 
  summarise(mean(current_age))
```

```{r proportion_women_apoe4_carrier}
avg_baseline_age = mci_baseline_df |> 
  summarise(
    tot_female = sum(sex == "female"), 
    female_carrier = sum(sex == "female",apoe4 == "carrier" )) |> 
      mutate(female_carrier_ratio = female_carrier / tot_female)|> 
      pull(female_carrier_ratio)
```


Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.

Only 8 individuals appeared in baseline_only and 16 individuals in amyloid_only. baseline_amyloid combines individuals who are in both mci_amyloid_df and mci_baseline_df and is then exported as baseline_amyloid.csv

```{r}
baseline_only = 
  anti_join(mci_baseline_df, mci_amyloid_df) |> 
  distinct(id) |> 
  nrow()
baseline_only
```

```{r}
amyloid_only = 
  anti_join(mci_amyloid_df, mci_baseline_df) |> 
  distinct(id) |> 
  nrow()
amyloid_only
```

```{r}
baseline_amyloid = 
  inner_join(mci_amyloid_df, mci_baseline_df, by = "id")
```


```{r}
write_csv(baseline_amyloid, file = "baseline_amyloid.csv")
```

